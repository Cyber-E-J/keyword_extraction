{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 14:16:32 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2022-11-07 14:16:32 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| pos       | combined  |\n",
      "| lemma     | combined  |\n",
      "| depparse  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2022-11-07 14:16:32 INFO: Use device: cpu\n",
      "2022-11-07 14:16:32 INFO: Loading: tokenize\n",
      "2022-11-07 14:16:32 INFO: Loading: pos\n",
      "2022-11-07 14:16:32 INFO: Loading: lemma\n",
      "2022-11-07 14:16:32 INFO: Loading: depparse\n",
      "2022-11-07 14:16:33 INFO: Loading: ner\n",
      "2022-11-07 14:16:33 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,depparse,ner' ,download_method = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(filename):\n",
    "    file = open(filename,\"r\")\n",
    "    lines = file.readlines()\n",
    "    dialogues = []\n",
    "    for line in lines:\n",
    "        dialogue_in = line.find(\"dialogue\")\n",
    "        if (dialogue_in!=-1):\n",
    "            dialogues.append(line.strip()[13:-2])\n",
    "    return dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = open_file(\"test.json\")\n",
    "test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keyphrase_from_file(file):\n",
    "    dialogues = []\n",
    "    for dialogue in file:\n",
    "        sentences = dialogue.split('\\\\n')\n",
    "        dialogues.append(sentences)\n",
    "\n",
    "    keyphrase = []\n",
    "    for dialogue in dialogues:\n",
    "        keyphrase.append(get_keyword_from_dialogue(dialogue))\n",
    "    return keyphrase\n",
    "\n",
    "\n",
    "# get_keyphrase_from_file(test_file[:34])\n",
    "# test_file[0]\n",
    "#get_keyword_from_dialogue(test_file[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keyphrase(filename):\n",
    "    file = open_file(filename)\n",
    "    return get_keyphrase_from_file(file)\n",
    "\n",
    "get_keyphrase(\"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = open_file(\"test.json\")\n",
    "#train_file = open_file(\"train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = []\n",
    "for dialogue in test_file:\n",
    "    if(dialogue.find('\\\\r\\\\n')>0 ):\n",
    "        sentences = dialogue.split('\\\\r\\\\n')\n",
    "    else: \n",
    "        sentences = dialogue.split('\\\\n')\n",
    "    all_sentences.append(sentences)\n",
    "\n",
    "# text = \"Alex: Were you able to attend Friday night's basketball game?\\\\r\\\\nBenjamin: I was unable to make it.\\\\r\\\\nAlex: You should have been there. It was intense.\\\\r\\\\nBenjamin: Is that right. Who ended up winning?\\\\r\\\\nAlex: Our team was victorious.\\\\r\\\\nBenjamin: I wish I was free that night.\"\n",
    "# text.find('\\\\r\\\\n')\n",
    "all_sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keyword_from_dialogue(dialogue):\n",
    "    keywords = []\n",
    "    for sentence in dialogue:\n",
    "        start_pos = sentence.find(\":\")\n",
    "        sentence = sentence[start_pos+2:]\n",
    "        for word in get_keyword_from_sentence(sentence):\n",
    "            keywords.append(word)\n",
    "    return keywords\n",
    "\n",
    "\n",
    "# dialogue = [\"Hannah: Hey, do you have Betty's number?\",\n",
    "#  'Amanda: Lemme check',\n",
    "#  'Hannah: <file_gif>',\n",
    "#  \"Amanda: Sorry, can't find it.\",\n",
    "#  'Amanda: Ask Larry',\n",
    "#  'Amanda: He called her last time we were at the park together',\n",
    "#  \"Hannah: I don't know him well\",\n",
    "#  'Hannah: <file_gif>',\n",
    "#  \"Amanda: Don't be shy, he's very nice\",\n",
    "#  'Hannah: If you say so..',\n",
    "#  \"Hannah: I'd rather you texted him\",\n",
    "#  'Amanda: Just text him ðŸ™‚',\n",
    "#  'Hannah: Urgh.. Alright',\n",
    "#  'Hannah: Bye',\n",
    "#  'Amanda: Bye bye']\n",
    "# print(get_keyword_from_dialogue(dialogue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "key_deprel = ['root', 'csubj', 'nsubj','xsubj', 'cop', 'vmod','dobj' ,'iobj', 'pobj']\n",
    "def get_keyword_from_sentence(sentence):\n",
    "    keywords = []\n",
    "    doc = nlp(sentence)\n",
    "    for sent in doc.sentences:\n",
    "        for word in sent.words:\n",
    "            if(word.deprel in key_deprel and word.text.lower() not in stop_words):\n",
    "                keywords.append(word.text)\n",
    "    return keywords\n",
    "\n",
    "get_keyword_from_sentence(\"I'd rather you texted him\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Barack Obama was born in Hawaii.  He was elected president in 2008.\"\n",
    "keywords = []\n",
    "doc = nlp(sentence)\n",
    "for sent in doc.sentences:\n",
    "        entities = sent.entities\n",
    "        entities_name = [entity.text for entity in entities]\n",
    "\n",
    "\n",
    "        for word in sent.words:\n",
    "            if(word.deprel in key_deprel and \n",
    "               word.text.lower() not in stop_words and\n",
    "               word in entities_name\n",
    "               ):\n",
    "                keywords.append(word.text)\n",
    "        #print(sent.ents)\n",
    "\n",
    "keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def legit_word(word):\n",
    "    if(word.deprel in key_deprel and \n",
    "       word.text.lower() not in stop_words\n",
    "       and word.type\n",
    "      ):\n",
    "        return True\n",
    "\n",
    "    else:\n",
    "         return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in sentences:\n",
    "    doc = nlp(sentence)\n",
    "    print(*[f'id: {word.id}\\tword: {word.text}\\tdeprel: {word.deprel}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Barack Obama was born in Hawaii.  John studies at Stanford University in NewYork.\")\n",
    "entities_name=[]\n",
    "for sentence in doc.sentences:\n",
    "    entities_name.append([entity.text for entity in sentence.entities])\n",
    "    \n",
    "entities_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Barack Obama was born in Hawaii.  He was elected president in 2008.\"\n",
    "keywords = []\n",
    "doc = nlp(sentence)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab34429e0a3bced58f8d8096e4933ac78bea0360b4c97ff6b772176bd5e9ef6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
